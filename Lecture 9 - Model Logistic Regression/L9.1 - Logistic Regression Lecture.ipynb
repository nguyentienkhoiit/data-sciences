{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Python\n",
    "\n",
    "For this lecture we will be working with the [Titanic Data Set from Kaggle](https://www.kaggle.com/c/titanic). This is a very famous data set and very often is a student's first step in machine learning! \n",
    "\n",
    "We'll be trying to predict a classification- survival or deceased.\n",
    "Let's begin our understanding of implementing Logistic Regression in Python for classification.\n",
    "\n",
    "We'll use a \"semi-cleaned\" version of the titanic data set, if you use the data set hosted directly on Kaggle, you may need to do some additional cleaning not shown in this lecture notebook.\n",
    "\n",
    "## Import Libraries\n",
    "Let's import some libraries to get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Ignore warning\n",
    "\n",
    "pd.set_option('float_format', '{:2f}'.format) # Show full number instead of show number like \"1.5e2\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Let's start by reading in the titanic_train.csv file into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data\\\\titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "sns.boxplot(x='Pclass', y='Age', data=df, palette='winter')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the wealthier passengers in the higher classes tend to be older, which makes sense. We'll use these median age values to impute based on Pclass for Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean of age each pclass:\n",
    "median1 = df[df['Pclass'] == 1]['Age'].median()\n",
    "median2 = df[df['Pclass'] == 2]['Age'].median()\n",
    "median3 = df[df['Pclass'] == 3]['Age'].median()\n",
    "\n",
    "median1, median2, median3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute age to each class:\n",
    "df.loc[(df['Pclass'] == 1) & (df['Age'].isna()), 'Age'] = median1\n",
    "df.loc[(df['Pclass'] == 2) & (df['Age'].isna()), 'Age'] = median2\n",
    "df.loc[(df['Pclass'] == 3) & (df['Age'].isna()), 'Age'] = median3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin field"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's go ahead and drop the Cabin column and the row in Embarked that is NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(columns='Cabin', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked field"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to drop the Embarked field because there were only two null values and you couldn‚Äôt use other fields to predict the missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop remaining NA values:\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Field 'sex': assigning male: 1; female: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Sex'] == 'male', 'Sex'] = 1\n",
    "df.loc[df['Sex'] == 'female', 'Sex'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Field 'Embarked': using 'get_dummy' (or OneHotEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pd.get_dummies()\n",
    "embark = pd.get_dummies(df['Embarked'])\n",
    "embark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ordinal encoder to \n",
    "oh_encoder = OneHotEncoder(sparse_output=False)\n",
    "embarked_enc = oh_encoder.fit_transform(df[['Embarked']])\n",
    "embarked_enc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show onehot categories:\n",
    "oh_encoder.categories_[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Combine with transformed data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot = pd.DataFrame(embarked_enc, columns= oh_encoder.categories_[0])\n",
    "df_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df, df_onehot], axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Drop unnecessary columns: `PassengerId`, `Name`, `Ticket`, `Embarked`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns:\n",
    "df2.drop(columns=['PassengerId','Embarked','Name','Ticket'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üòâ Great! Our data is ready for our model!\n",
    "\n",
    "# Building a Logistic Regression model\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.saedsayad.com/images/LogReg_1.png\" width=\"600\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Similar to linear regression, `logistic regression` is also used to` estimate the relationship between a dependent variable` and `one or more independent variables`, but it is used to make a prediction about a `categorical variable` versus a continuous one. A categorical variable can be true or false, yes or no, 1 or 0, et cetera. The unit of measure also differs from linear regression as `it produces a probability`, but the logit function transforms the S-curve into straight line.\n",
    "\n",
    "+ As default, Sklearn Logistic Regression uses 0.5 as the threshold to classify 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df2.drop(columns='Survived'), \n",
    "                                                    df2['Survived'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=101)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg1 = LogisticRegression()\n",
    "logreg1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make prediction and return result as label:\n",
    "y_train_pred = logreg1.predict(X_train)\n",
    "y_test_pred = logreg1.predict(X_test)\n",
    "\n",
    "# Make prediction and return result as probability:\n",
    "y_train_pred_prop = logreg1.predict_proba(X_train)\n",
    "y_test_pred_prop = logreg1.predict_proba(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look in our results:\n",
    "print('Result of \".predict(X_train)\":', y_train_pred[:5], sep = '\\n')\n",
    "print('=='*30)\n",
    "print('Result of \".predict_proba(X_train)\":', y_train_pred_prop[:5], sep = '\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import evaluation metrics:\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üëâ Accuracy metrics\n",
    "The ratio between the number of correctly predicted points and the total number of points in the data set. \n",
    "\n",
    "It's simple! Right :))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on trainset:\n",
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on testset:\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üëâ Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating non-normalized confustion matrix on Testset:\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confustion matrix on Testset\n",
    "confusion_matrix(y_test, y_test_pred, normalize='true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (11, 4))\n",
    "plt.subplot(121)\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "df_cm = pd.DataFrame(conf_matrix, columns=np.unique(['Negative (0)', 'Positive (1)']), \n",
    "                     index = np.unique(['Negative (0)', 'Positive (1)']))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})\n",
    "\n",
    "plt.subplot(122)\n",
    "conf_matrix_norm = confusion_matrix(y_test, y_test_pred, normalize='true')\n",
    "df_cm = pd.DataFrame(conf_matrix_norm, columns=np.unique(['Negative (0)', 'Positive (1)']), \n",
    "                     index = np.unique(['Negative (0)', 'Positive (1)']))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 14})\n",
    "plt.suptitle('CONFUSION MATRIX')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ **Type 1 and Type 2 errors**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3NycrFcQRWBY"
   },
   "source": [
    "![alt text](https://www.statisticssolutions.com/wp-content/uploads/2017/12/rachnovblog.jpg)\n",
    "\n",
    "source: https://www.statisticssolutions.com/to-err-is-human-what-are-type-i-and-ii-errors/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9ssxfPvg5Qh5"
   },
   "source": [
    "+ **Type 1 error** (**False Positive**), X·∫£y ra khi gi·∫£ thuy·∫øt **th·ª±c ch·∫•t l√† sai** nh∆∞ng **ƒë∆∞·ª£c cho l√† ƒë√∫ng**\n",
    "\n",
    "    *+ V√≠ d·ª•:* B·∫°n x√¢y d·ª±ng model ƒë·ªÉ d·ª± ƒëo√°n b·ªánh nh√¢n c√≥ b·ªã covid hay kh√¥ng (Trong ƒë√≥, positive l√† kh·ªèe m·∫°nh v√† negative l√† b·ªã covid). \n",
    "    \n",
    "    N·∫øu model d·ª± ƒëo√°n b·ªánh nh√¢n kh·ªèe m·∫°nh nh∆∞ng th·ª±c t·∫ø h·ªç c√≥ b·ªã th√¨ ƒë√≥ ƒë∆∞·ª£c g·ªçi l√† m·ªôt Type 1 error\n",
    "\n",
    "+ **Type 2 error** (**False Negative**), x·∫£y ra khi gi·∫£ thuy·∫øt **th·ª±c ch·∫•t l√† ƒë√∫ng** nh∆∞ng **ƒë∆∞·ª£c cho l√† sai**\n",
    "\n",
    "    *+ V√≠ d·ª•:* B·∫°n x√¢y d·ª±ng model ƒë·ªÉ d·ª± ƒëo√°n b·ªánh nh√¢n c√≥ b·ªã covid hay kh√¥ng (Trong ƒë√≥, positive l√† kh·ªèe m·∫°nh v√† negative l√† b·ªã covid). \n",
    "    \n",
    "    N·∫øu model d·ª± ƒëo√°n b·ªánh nh√¢n b·ªã covid nh∆∞ng th·ª±c t·∫ø h·ªç l·∫°i kh√¥ng b·ªã th√¨ ƒë√≥ ƒë∆∞·ª£c g·ªçi l√† m·ªôt Type 2 error*\n",
    "\n",
    "Th√¥ng th∆∞·ªùng ch√∫ng ta c·∫ßn xem x√©t vi·ªác gi·∫£m c·∫£ 2 lo·∫°i l·ªói n√†y ƒë·ªÉ model c·ªßa ch√∫ng ta ƒë·∫°t hi·ªáu qu·∫£ cao nh·∫•t\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tgZXvm79MzlY"
   },
   "source": [
    "### Terminologies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "k5XVughUMb0O"
   },
   "source": [
    "**Recall, sensitivity, hit rate, or true positive rate(TPR)**: l√† t·ªâ l·ªá s·ªë ƒëi·ªÉm true positive trong s·ªë nh·ªØng ƒëi·ªÉm th·ª±c s·ª± l√† positive (TP + FN). Hay n√≥i c√°ch kh√°c l√† t·ªâ l·ªá model d·ª± ƒëo√°n ƒë√∫ng l√† Positive (1) tr√™n t·ªïng s·ªë th·ª±c t·∫ø Positive (1) c·ªßa data\n",
    "\n",
    "ƒê·ªÉ tƒÉng Recall ta c·∫ßn gi·∫£m FN, t·ª©c l√† gi·∫£m Type 2 error\n",
    "\n",
    "\n",
    "$$\n",
    "Recall = \\frac{TP}{P} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "**Precision or positive predictive value (PPV)**: l√† t·ªâ l·ªá s·ªë ƒëi·ªÉm true positive trong s·ªë nh·ªØng ƒëi·ªÉm ƒë∆∞·ª£c ph√¢n lo·∫°i l√† positive c·ªßa model (TP + FP). Hay n√≥i c√°ch kh√°c l√† t·ªâ l·ªá model d·ª± ƒëo√°n ƒë√∫ng l√† Positive (1) tr√™n t·ªïng s·ªë d·ª± ƒëo√°n l√† Positive (1) c·ªßa model \n",
    "\n",
    "ƒê·ªÉ tƒÉng Precision ta c·∫ßn gi·∫£m FP, t·ª©c l√† gi·∫£m Type 1 error\n",
    "\n",
    "$$\n",
    "Precision = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "\n",
    "**F1 score**: the **harmonic mean** of **precision** and **recall**\n",
    "\n",
    "$$\n",
    "F_1 = 2 \\frac{Precision . Recall}{Precision + Recall}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check `precision`, `recall`, `f1-score` using `classification report`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î Note: If you curious about `macro avg` and `weight avg` and here is the answer:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ In the case of **Weighted average** the performance metrics are weighted accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Weight Avg. of recall (The same with Precision):\n",
    "# (Percentage_of_positive)*Positive_Recall + (Percentage_of_Negative)*Negative_Recall\n",
    "\n",
    "(71/178)*0.66 + (107/178)*0.92"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ In the case of **Macro average** is just the **mean** of metrics of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Macro Avg. of recall (The same with Precision):\n",
    "# (Positive_Recall + Negative_Recall)/2\n",
    "\n",
    "(0.66 + 0.92)/2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§î Let's try to train model without `Parch` column and Use SMOTE OverSampling technique "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Drop Parch column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.drop(columns = 'Parch')\n",
    "df3.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Use SMOTE OVERSAMPLING technique\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/347937180/figure/fig3/AS:973429209563136@1609095017080/Illustration-of-the-SMOTE-oversampling-approach.ppm\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df3.drop(columns='Survived')\n",
    "y = df3['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install imblearn library\n",
    "! pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# X v√† y l√† c√°c feature v√† label c·ªßa d·ªØ li·ªáu\n",
    "smote = SMOTE(k_neighbors = 3, random_state=96)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled.shape, y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check value count of label:\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_resampled, \n",
    "                                                    y_resampled, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=101,\n",
    "                                                    stratify = y_resampled)\n",
    "\n",
    "X_train1.shape, y_train1.shape, X_test1.shape, y_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model:\n",
    "logreg2 = LogisticRegression()\n",
    "# Train model:\n",
    "logreg2.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on trainset and testset:\n",
    "y_test_pred1 = logreg2.predict(X_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "# Plot before drop parch col:\n",
    "plt.subplot(221)\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "df_cm = pd.DataFrame(conf_matrix, columns=np.unique(['Negative (0)', 'Positive (1)']), \n",
    "                     index = np.unique(['Negative (0)', 'Positive (1)']))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16}, cbar = False)\n",
    "plt.title('CONFUSION MATRIX (before drop PARCH)')\n",
    "\n",
    "plt.subplot(222)\n",
    "conf_matrix_norm = confusion_matrix(y_test, y_test_pred, normalize='true')\n",
    "df_cm = pd.DataFrame(conf_matrix_norm, columns=np.unique(['Negative (0)', 'Positive (1)']), \n",
    "                     index = np.unique(['Negative (0)', 'Positive (1)']))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 14}, cbar = False)\n",
    "\n",
    "# Plot after drop parch cols:\n",
    "plt.subplot(223)\n",
    "conf_matrix = confusion_matrix(y_test1, y_test_pred1)\n",
    "df_cm = pd.DataFrame(conf_matrix, columns=np.unique(['Negative (0)', 'Positive (1)']), \n",
    "                     index = np.unique(['Negative (0)', 'Positive (1)']))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "sns.heatmap(df_cm, cmap=\"Greens\", annot=True,annot_kws={\"size\": 16}, cbar = False)\n",
    "plt.title('CONFUSION MATRIX (after drop PARCH)')\n",
    "\n",
    "plt.subplot(224)\n",
    "conf_matrix_norm = confusion_matrix(y_test1, y_test_pred1, normalize='true')\n",
    "df_cm = pd.DataFrame(conf_matrix_norm, columns=np.unique(['Negative (0)', 'Positive (1)']), \n",
    "                     index = np.unique(['Negative (0)', 'Positive (1)']))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "sns.heatmap(df_cm, cmap=\"Greens\", annot=True,annot_kws={\"size\": 14}, cbar = False)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification after drop \"Parch\" and Over sampling')\n",
    "print(classification_report(y_test1,y_test_pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification before drop \"Parch\" and Over sampling')\n",
    "print(classification_report(y_test,y_test_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's predict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A customer has data like this:\n",
    "+ Pclass: 2\n",
    "+ Sex: 1\n",
    "+ Age: 25\n",
    "+ SibSp: 0\n",
    "+ Parch: 1\n",
    "+ Fare: 70\n",
    "+ Embarked: Q\n",
    "\n",
    "Will be alive or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f90745bbca20a4cb7db8559fdb79554de2a76cb1e5146bbf788699cf2d961a52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
